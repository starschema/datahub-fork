# Docker compose file covering DataHub's default configuration, which is to run all containers on a single host.

# Please see the README.md for instructions as to how to use and customize.

# NOTE: This file does not build! No dockerfiles are set. See the README.md in this directory.
---
services:
  datahub-frontend-react:
    hostname: datahub-frontend-react
    image: ${DATAHUB_FRONTEND_IMAGE:-acryldata/datahub-frontend-react}:${DATAHUB_VERSION:-head}
    ports:
    - ${DATAHUB_MAPPED_FRONTEND_PORT:-9002}:9002
    build:
      context: ../
      dockerfile: docker/datahub-frontend/Dockerfile
    env_file: datahub-frontend/env/docker.env
    depends_on:
      datahub-gms:
        condition: service_healthy
    volumes:
    - ${HOME}/.datahub/plugins:/etc/datahub/plugins
  datahub-actions:
    hostname: actions
    image: ${DATAHUB_ACTIONS_IMAGE:-acryldata/datahub-actions}:${DATAHUB_VERSION:-head}-slim
    build:
      context: ../
      dockerfile: docker/datahub-actions/Dockerfile
    env_file: datahub-actions/env/docker.env
    environment:
    - ACTIONS_EXTRA_PACKAGES=${ACTIONS_EXTRA_PACKAGES:-}
    - ACTIONS_CONFIG=${ACTIONS_CONFIG:-}
    depends_on:
      datahub-gms:
        condition: service_healthy
  datahub-gms:
    hostname: datahub-gms
    image: ${DATAHUB_GMS_IMAGE:-acryldata/datahub-gms}:${DATAHUB_VERSION:-head}
    environment:
      - DATAHUB_SERVER_TYPE=${DATAHUB_SERVER_TYPE:-quickstart}
      - DATAHUB_TELEMETRY_ENABLED=${DATAHUB_TELEMETRY_ENABLED:-true}
      - EBEAN_DATASOURCE_DRIVER=com.mysql.jdbc.Driver
      - EBEAN_DATASOURCE_HOST=mysql:3306
      - EBEAN_DATASOURCE_PASSWORD=datahub
      - EBEAN_DATASOURCE_URL=jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8&enabledTLSProtocols=TLSv1.2
      - EBEAN_DATASOURCE_USERNAME=datahub
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX=true
      - ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX=true
      - ENTITY_REGISTRY_CONFIG_PATH=/datahub/datahub-gms/resources/entity-registry.yml
      - GRAPH_SERVICE_IMPL=elasticsearch
      - GRAPH_SERVICE_DIFF_MODE_ENABLED=true
      - JAVA_OPTS=-Xms1g -Xmx1g
      - KAFKA_BOOTSTRAP_SERVER=broker:29092
      - KAFKA_SCHEMAREGISTRY_URL=http://schema-registry:8081
      - KAFKA_CONSUMER_STOP_ON_DESERIALIZATION_ERROR=${KAFKA_CONSUMER_STOP_ON_DESERIALIZATION_ERROR:-true}
      - MAE_CONSUMER_ENABLED=true
      - MCE_CONSUMER_ENABLED=true
      - METADATA_SERVICE_AUTH_ENABLED=${METADATA_SERVICE_AUTH_ENABLED:-false}
      - PE_CONSUMER_ENABLED=true
      - UI_INGESTION_ENABLED=true
    ports:
    - ${DATAHUB_MAPPED_GMS_PORT:-8080}:8080
    build:
        context: ../
        dockerfile: docker/datahub-gms/Dockerfile
    healthcheck:
      test: curl -sS --fail http://datahub-gms:${DATAHUB_GMS_PORT:-8080}/health
      start_period: 90s
      interval: 1s
      retries: 3
      timeout: 5s
    depends_on:
      datahub-upgrade:
        condition: service_completed_successfully
    volumes:
    - ${HOME}/.datahub/plugins:/etc/datahub/plugins
  datahub-upgrade:
    hostname: datahub-upgrade
    image: ${DATAHUB_UPGRADE_IMAGE:-acryldata/datahub-upgrade}:${DATAHUB_VERSION:-head}
    command:
    - -u
    - SystemUpdate
    build:
      context: ../
      dockerfile: docker/datahub-upgrade/Dockerfile
    environment:
      - EBEAN_DATASOURCE_DRIVER=com.mysql.jdbc.Driver
      - EBEAN_DATASOURCE_HOST=mysql:3306
      - EBEAN_DATASOURCE_PASSWORD=datahub
      - EBEAN_DATASOURCE_URL=jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8
      - EBEAN_DATASOURCE_USERNAME=datahub
      - ELASTICSEARCH_BUILD_INDICES_CLONE_INDICES=false
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX=true
      - ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX=true
      - ELASTICSEARCH_PORT=9200
      - ENTITY_REGISTRY_CONFIG_PATH=/datahub/datahub-gms/resources/entity-registry.yml
      - GRAPH_SERVICE_IMPL=elasticsearch
      - KAFKA_BOOTSTRAP_SERVER=broker:29092
      - KAFKA_SCHEMAREGISTRY_URL=http://schema-registry:8081
    labels:
      datahub_setup_job: true
    depends_on:
      elasticsearch-setup:
        condition: service_completed_successfully
      kafka-setup:
        condition: service_completed_successfully
      mysql-setup:
        condition: service_completed_successfully
  # This "container" is a workaround to pre-create search indices
  elasticsearch-setup:
    hostname: elasticsearch-setup
    image: ${DATAHUB_ELASTIC_SETUP_IMAGE:-acryldata/datahub-elasticsearch-setup}:${DATAHUB_VERSION:-head}
    build:
      context: ../
      dockerfile: docker/elasticsearch-setup/Dockerfile
    env_file: elasticsearch-setup/env/docker.env
    environment:
      - ELASTICSEARCH_USE_SSL=${ELASTICSEARCH_USE_SSL:-false}
      - USE_AWS_ELASTICSEARCH=${USE_AWS_ELASTICSEARCH:-false}
    depends_on:
      elasticsearch:
        condition: service_healthy
    labels:
      datahub_setup_job: true
  # This "container" is a workaround to pre-create topics.
  # This is not required in most cases, kept here for backwards compatibility with older clients that
  # explicitly wait for this container
  kafka-setup:
    hostname: kafka-setup
    image: ${DATAHUB_KAFKA_SETUP_IMAGE:-acryldata/datahub-kafka-setup}:${DATAHUB_VERSION:-head}
    build:
      dockerfile: ./docker/kafka-setup/Dockerfile
      context: ../
    env_file: kafka-setup/env/docker.env
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    labels:
      datahub_setup_job: true
  elasticsearch:
    hostname: elasticsearch
    image: ${DATAHUB_SEARCH_IMAGE:-elasticsearch}:${DATAHUB_SEARCH_TAG:-7.16.1}
    ports:
    - ${DATAHUB_MAPPED_ELASTIC_PORT:-9200}:9200
    env_file: elasticsearch/env/docker.env
    environment:
    - discovery.type=single-node
    - ${XPACK_SECURITY_ENABLED:-xpack.security.enabled=false}
    deploy:
      resources:
        limits:
          memory: 1G
    healthcheck:
      test: curl -sS --fail http://elasticsearch:$${DATAHUB_ELASTIC_PORT:-9200}/_cluster/health?wait_for_status=yellow&timeout=0s
      start_period: 20s
      interval: 1s
      retries: 3
      timeout: 5s
    volumes:
    - esdata:/usr/share/elasticsearch/data
  mysql:
    hostname: mysql
    image: mysql:${DATAHUB_MYSQL_VERSION:-8.2}
    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_bin --default-authentication-plugin=mysql_native_password
    ports:
    - ${DATAHUB_MAPPED_MYSQL_PORT:-3306}:3306
    environment:
    - MYSQL_DATABASE=datahub
    - MYSQL_USER=datahub
    - MYSQL_PASSWORD=datahub
    - MYSQL_ROOT_PASSWORD=datahub
    - MYSQL_ROOT_HOST=%
    restart: on-failure
    healthcheck:
      test: mysqladmin ping -h mysql -u $$MYSQL_USER --password=$$MYSQL_PASSWORD
      start_period: 60s
      interval: 10s
      retries: 30
      timeout: 10s
    volumes:
    - mysqldata:/var/lib/mysql
  mysql-setup:
    hostname: mysql-setup
    image: ${DATAHUB_MYSQL_SETUP_IMAGE:-acryldata/datahub-mysql-setup}:${DATAHUB_VERSION:-head}
    environment:
    - MYSQL_HOST=mysql
    - MYSQL_PORT=3306
    - MYSQL_USERNAME=datahub
    - MYSQL_PASSWORD=datahub
    - DATAHUB_DB_NAME=datahub
    depends_on:
      mysql:
        condition: service_healthy
    labels:
      datahub_setup_job: true
  schema-registry:
    hostname: schema-registry
    image: ${DATAHUB_CONFLUENT_SCHEMA_REGISTRY_IMAGE:-confluentinc/cp-schema-registry}:${DATAHUB_CONFLUENT_VERSION:-7.9.2}
    ports:
    - ${DATAHUB_MAPPED_SCHEMA_REGISTRY_PORT:-8081}:8081
    env_file: schema-registry/env/docker.env
    healthcheck:
      test: nc -z schema-registry ${DATAHUB_SCHEMA_REGISTRY_PORT:-8081}
      start_period: 60s
      interval: 1s
      retries: 3
      timeout: 5s
    depends_on:
      broker:
        condition: service_healthy
  broker:
    hostname: broker
    image: ${DATAHUB_CONFLUENT_KAFKA_IMAGE:-confluentinc/cp-kafka}:${DATAHUB_CONFLUENT_VERSION:-7.9.2}
    ports:
    - ${DATAHUB_MAPPED_KAFKA_BROKER_PORT:-9092}:9092
    env_file: broker/env/docker.env
    healthcheck:
      test: nc -z broker $${DATAHUB_KAFKA_BROKER_PORT:-9092}
      start_period: 60s
      interval: 1s
      retries: 5
      timeout: 5s
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
    - broker:/var/lib/kafka/data/
  zookeeper:
    hostname: zookeeper
    image: ${DATAHUB_CONFLUENT_ZOOKEEPER_IMAGE:-confluentinc/cp-zookeeper}:${DATAHUB_CONFLUENT_VERSION:-7.9.2}
    ports:
    - ${DATAHUB_MAPPED_ZK_PORT:-2181}:2181
    env_file: zookeeper/env/docker.env
    healthcheck:
      test: echo srvr | nc zookeeper $${DATAHUB_ZK_PORT:-2181}
      start_period: 10s
      interval: 5s
      retries: 3
      timeout: 5s
    volumes:
    # See https://stackoverflow.com/a/61008432 for why we need two volumes.
    # See also: https://docs.confluent.io/platform/current/installation/docker/operations/external-volumes.html#data-volumes-for-kafka-and-zk
    - zkdata:/var/lib/zookeeper/data
    - zklogs:/var/lib/zookeeper/log
networks:
  default:
    name: datahub_network
volumes:
  esdata:
  mysqldata:
  broker:
  zkdata:
  zklogs:
